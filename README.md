<br>



  

<h1 align="center">Canine Femur Fracture Classification</h1>

  

<p align="center">

Â  An AI-powered system to accurately classify canine femur fractures from X-ray images into <strong>Oblique</strong> and <strong>Overriding</strong> categories using state-of-the-art Deep Learning models.

Â  <br>

Â  <br>

Â  <a href="#-key-features">Key Features</a> â€¢

Â  <a href="#-project-pipeline">Pipeline</a> â€¢

Â  <a href="#-results">Results</a> â€¢

Â  <a href="#-getting-started">Getting Started</a> â€¢

Â  <a href="#-usage">Usage</a> â€¢

Â  <a href="#-acknowledgments">Acknowledgments</a>

</p>

  

<p align="center">

Â  <img src="https://img.shields.io/badge/Python-3.12+-blue.svg" alt="Python Version">

Â  <img src="https://img.shields.io/badge/TensorFlow-2.x-orange.svg" alt="TensorFlow">

Â  <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License">

</p>

  

---

  

## ğŸ“– About The Project

  

This project provides a complete, end-to-end solution for the automated classification of dog femur fractures. By leveraging computer vision and deep learning, it aims to assist veterinary professionals in diagnosing fracture types from X-ray images with high accuracy. The system processes raw radiographs, isolates the femur, and uses a suite of powerful Convolutional Neural Networks (CNNs) to deliver a fast and reliable classification.

  

This repository contains all the necessary code, from data preprocessing and model training to a ready-to-use desktop application for real-time predictions.

  

---

  

## âœ¨ Key Features

  

* Â  **ğŸ¦´ Automated Femur Segmentation:** Removes yellow squares to isolate the femur bone.

* Â  **ğŸ”„ Data Augmentation & Balancing:** Robustly increases dataset diversity and prevents class imbalance for better model generalization.

* Â  **ğŸ§  Multiple CNN Architectures:** Implements and compares several renowned models:

Â  Â  * Â  VGG16 / VGG19

Â  Â  * Â  ResNet50

Â  Â  * Â  MobileNetV2

Â  Â  * Â  Xception

Â  Â  * Â  EfficientNetB0

Â  Â  * Â  DenseNet121

* Â  **ğŸš€ High Performance:** Achieves over 99% accuracy, precision, and recall in classifying fractures.

* Â  **ğŸ–¥ï¸ Desktop GUI:** An intuitive graphical user interface for easy, real-time classification without needing to code.

  

---

  

## âš™ï¸ Project Pipeline

  

The project follows a systematic pipeline to ensure robust and reproducible results.

  

**Raw X-ray â†’ Segmentation â†’ Augmentation â†’ Balancing â†’ Model Training â†’ Prediction**

  

1. Â **Data Preprocessing & Segmentation (`01-Segmentation/`)**

Â  Â  The initial step processes raw X-ray images. A segmentation algorithm is applied to automatically detect and crop the region of interest (the femur bone), reducing noise and focusing the models on relevant features.

  

2. Â **Data Augmentation (`02-Augmentation/`)**

Â  Â  To create a more robust training set and prevent overfitting, various data augmentation techniques (e.g., rotation, flipping, zooming) are applied to the segmented images.

  

3. Â **Data Balancing (`03-Data-Balancing/`)**

Â  Â  The dataset is carefully balanced to ensure an equal number of samples for both the "Oblique" and "Overriding" fracture classes. This is critical for training an unbiased model.

  

4. Â **Model Training & Evaluation (`04-Modeling/`)**

Â  Â  This core stage involves training multiple CNN architectures using both feature extraction and fine-tuning methods. Each model's performance is rigorously evaluated using standard classification metrics.

  

---

  

## ğŸ“Š Results

  

The trained models demonstrated exceptional performance on the validation set. The fine-tuned **ResNet50** model emerged as the top performer.

  

![Accuracy image](accuracy.png)

  

*All trained models are available in the `05-Saved-Models/` directory.*

  

---

  

## ğŸ—‚ï¸ Project Structure

  

```

.

â”œâ”€â”€ 00-The-DataSet/

â”‚ Â  â”œâ”€â”€ 00-Dogs-Femur-Fracture/ Â  Â  # Raw X-ray images

â”‚ Â  â”œâ”€â”€ Augmented_DataSet/ Â  Â  Â  Â  Â # Output of the augmentation script

â”‚ Â  â”œâ”€â”€ Balanced_DataSet/ Â  Â  Â  Â  Â  # Output of the balancing script

â”‚ Â  â””â”€â”€ Dataset_split/ Â  Â  Â  Â  Â  Â  Â # Final train/validation/test split

â”œâ”€â”€ 01-Segmentation/ Â  Â  Â  Â  Â  Â  Â  Â # Scripts for femur segmentation

â”œâ”€â”€ 02-Augmentation/ Â  Â  Â  Â  Â  Â  Â  Â # Scripts for data augmentation

â”œâ”€â”€ 03-Data-Balancing/ Â  Â  Â  Â  Â  Â  Â # Scripts for balancing classes

â”œâ”€â”€ 04-Modeling/ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Jupyter notebooks for model training

â”œâ”€â”€ 05-Saved-Models/ Â  Â  Â  Â  Â  Â  Â  Â # Trained models in .h5 format

â”œâ”€â”€ Desktop-Application/ Â  Â  Â  Â  Â  Â # Source code for the GUI application

â”œâ”€â”€ requirements.txt Â  Â  Â  Â  Â  Â  Â  Â # Project dependencies

â””â”€â”€ README.md Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # This file

```

  

---

  

## ğŸš€ Getting Started

  

To get a local copy up and running, follow these simple steps.

  

### Prerequisites

  

* Â  Python 3.10+

* Â  Git

  

### Installation

  

1. Â **Clone the repository:**

    ```sh

    git clone https://github.com/ahmedxxzz/The-Graduation-Project

    ```

  

2. Â **Create and activate a virtual environment (recommended):**

    ```sh

    Â  # For macOS/Linux

    Â  python3 -m venv venv

    Â  source venv/bin/activate

    ```

Â  Â  # For Windows

```sh

python -m venv venv

venv\Scripts\activate

```

  

3. Â **Install the required packages:**

```sh

pip install -r requirements.txt

```

  

---

  

## â–¶ï¸ Usage

  

You can use the trained models in two ways: through the desktop application or by integrating the model into your own Python scripts.

  

### 1. Desktop Application

  

The easiest way to perform a classification is with the provided GUI.

  

1. Â Navigate to the application directory:

```sh

Â  Â  cd Desktop-Application/

```

2. Â Run the application:

```sh

Â  Â  python main.py Â # or the relevant main script name

```

3. Â Click the "Upload Image" button, select a canine X-ray, and the model will predict the fracture type.

  
  

---

  

## ğŸ“ Acknowledgments

  

This work was developed as a graduation project for the Faculty of Computers Science and Artificial Intelligence at the **University of Sadat City**. We extend our gratitude to our supervisors and the university for their support.