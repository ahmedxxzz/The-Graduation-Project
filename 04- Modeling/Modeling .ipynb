{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from IPython.core.getipython import get_ipython\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19, ResNet50, VGG16, MobileNetV2, Xception, EfficientNetB0, DenseNet121\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg19_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenetv2_preprocess\n",
    "from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnetb0_preprocess\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet121_preprocess\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout,Dense, BatchNormalization,Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report, f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_dataset(source_dir, output_dir, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Splits each image class in the source_dir into train, validation, and test directories.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    train_dir = os.path.join(output_dir, \"train\")\n",
    "    val_dir   = os.path.join(output_dir, \"validation\")\n",
    "    test_dir  = os.path.join(output_dir, \"test\")\n",
    "    \n",
    "    for dir_path in [train_dir, val_dir, test_dir]:\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "    # Get the list of classes, each class is a subdirectory in the source directory\n",
    "    classes = [d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))]\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_src = os.path.join(source_dir, class_name)\n",
    "        images = [f for f in os.listdir(class_src) if os.path.isfile(os.path.join(class_src, f))]\n",
    "        random.shuffle(images)\n",
    "        \n",
    "        total = len(images)\n",
    "        train_end = int(total * train_ratio)\n",
    "        val_end   = train_end + int(total * val_ratio)\n",
    "        \n",
    "        splits = {\n",
    "            \"train\": images[:train_end],\n",
    "            \"validation\": images[train_end:val_end],\n",
    "            \"test\": images[val_end:]\n",
    "        }\n",
    "        \n",
    "        for split, file_list in splits.items():\n",
    "            class_dst = os.path.join(output_dir, split, class_name)\n",
    "            if not os.path.exists(class_dst):\n",
    "                os.makedirs(class_dst)\n",
    "            for file_name in file_list:\n",
    "                src_file = os.path.join(class_src, file_name)\n",
    "                dst_file = os.path.join(class_dst, file_name)\n",
    "                shutil.copy2(src_file, dst_file)\n",
    "    print(f\"Dataset split into train, validation, and test in '{output_dir}'.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(Pretrained_model):\n",
    "    x = Pretrained_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(1, activation='sigmoid', dtype='float32')(x)\n",
    "    return Model(inputs=Pretrained_model.input, outputs=predictions)\n",
    "\n",
    "def train_and_evaluate_model(model_name, preprocess_function):\n",
    "    print(f\"\\nTraining with {model_name}...\\n\")\n",
    "    \n",
    "    if model_name == 'Xception':\n",
    "        img_h, img_w = 299, 299\n",
    "    else:\n",
    "        img_h, img_w = 224, 224\n",
    "\n",
    "    # Create ImageDataGenerators for each split\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_function)\n",
    "    val_datagen   = ImageDataGenerator(preprocessing_function=preprocess_function)\n",
    "    test_datagen  = ImageDataGenerator(preprocessing_function=preprocess_function)\n",
    "    \n",
    "    # Define paths to the split dataset directories\n",
    "    train_dir = os.path.join(split_dataset_dir, \"train\")\n",
    "    val_dir   = os.path.join(split_dataset_dir, \"validation\")\n",
    "    test_dir  = os.path.join(split_dataset_dir, \"test\")\n",
    "    \n",
    "    # Data generators for each split\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_h, img_w),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "    )\n",
    "    \n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(img_h, img_w),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False,\n",
    "        seed=42,\n",
    "    )\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_h, img_w),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False  ,\n",
    "    )\n",
    "    \n",
    "    class_indices = test_generator.class_indices    \n",
    "    \n",
    "    # Load the chosen pretrained model as the base\n",
    "    if model_name == 'VGG19':\n",
    "        Pretrained_model = VGG19(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'ResNet50':\n",
    "        Pretrained_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'VGG16':\n",
    "        Pretrained_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'MobileNetV2':\n",
    "        Pretrained_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'Xception':\n",
    "        Pretrained_model = Xception(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'EfficientNetB0':\n",
    "        Pretrained_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'DenseNet121':\n",
    "        Pretrained_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "    \n",
    "    # Freeze the Pretrained_model layers\n",
    "    Pretrained_model.trainable = False\n",
    "    model = build_model(Pretrained_model)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=math.ceil(train_generator.samples / batch_size),\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=math.ceil(val_generator.samples / batch_size),\n",
    "        callbacks=[early_stopping],\n",
    "          )\n",
    "    \n",
    "    # evaluate on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)    \n",
    "    print(f\"\\n{model_name} Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"{model_name} Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(test_generator, verbose=1)\n",
    "    y_pred = (predictions > 0.5).astype(int).flatten()\n",
    "    y_true = test_generator.classes\n",
    "    \n",
    "    # Compute performance metrics\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    \n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "    precision = precision_score(y_true, y_pred, average='binary')\n",
    "    recall = recall_score(y_true, y_pred, average='binary')\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    labels = list(class_indices.keys())\n",
    "    print(classification_report(y_true, y_pred, target_names=labels))\n",
    "    \n",
    "    # Compute ROC Curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, predictions.flatten()) \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'history': history.history,\n",
    "        'confusion_matrix': cm,\n",
    "        'roc': (fpr, tpr, roc_auc),\n",
    "        'performance': {'accuracy': test_accuracy, 'f1': f1, 'precision': precision, 'recall': recall},\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def plot_results(results, run_dir):\n",
    "    model_names = list(results.keys())\n",
    "    num_models = len(model_names)\n",
    "    \n",
    "    # 1. Plot Confusion Matrices\n",
    "    fig_cm, axes_cm = plt.subplots(1, num_models, figsize=(5*num_models, 4))\n",
    "    if num_models == 1:\n",
    "        axes_cm = [axes_cm]\n",
    "    for ax, name in zip(axes_cm, model_names):\n",
    "        cm = results[name]['confusion_matrix']\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        ax.set_title(f\"{name} Confusion Matrix\")\n",
    "        tick_marks = np.arange(len(results[name]['labels']))\n",
    "        ax.set_xticks(tick_marks)\n",
    "        ax.set_xticklabels(results[name]['labels'], rotation=45)\n",
    "        ax.set_yticks(tick_marks)\n",
    "        ax.set_yticklabels(results[name]['labels'])\n",
    "        thresh = cm.max() / 2.0\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        fig_cm.colorbar(im, ax=ax)\n",
    "    fig_cm.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig_cm.suptitle(\"Confusion Matrices\", fontsize=16)\n",
    "    plt.savefig(os.path.join(run_dir, \"confusion_matrices.png\"))\n",
    "    plt.close(fig_cm)\n",
    "    \n",
    "    # 2. Plot ROC Curves\n",
    "    fig_roc, axes_roc = plt.subplots(1, num_models, figsize=(5*num_models, 4))\n",
    "    if num_models == 1:\n",
    "        axes_roc = [axes_roc]\n",
    "    for ax, name in zip(axes_roc, model_names):\n",
    "        fpr, tpr, roc_auc = results[name]['roc']\n",
    "        ax.plot(fpr, tpr, lw=2, label=f\"AUC = {roc_auc:.2f}\")\n",
    "        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title(f\"ROC Curve - {name}\")\n",
    "        ax.legend(loc=\"lower right\")\n",
    "    fig_roc.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig_roc.suptitle(\"ROC Curves\", fontsize=16)\n",
    "    plt.savefig(os.path.join(run_dir, \"roc_curves.png\"))\n",
    "    plt.close(fig_roc)\n",
    "    \n",
    "    # 3. Plot Accuracy and Loss Curves for each model\n",
    "    for name in model_names:\n",
    "        history = results[name]['history']\n",
    "        epochs_range = range(1, len(history['accuracy']) + 1)\n",
    "        fig_model, (ax_acc, ax_loss) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        ax_acc.plot(epochs_range, history['accuracy'], marker='o', label='Train Accuracy')\n",
    "        ax_acc.plot(epochs_range, history['val_accuracy'], marker='x', linestyle='--', label='Validation Accuracy')\n",
    "        ax_acc.set_title(f\"{name} Accuracy\")\n",
    "        ax_acc.set_xlabel('Epoch')\n",
    "        ax_acc.set_ylabel('Accuracy')\n",
    "        ax_acc.legend()\n",
    "        \n",
    "        ax_loss.plot(epochs_range, history['loss'], marker='o', label='Train Loss')\n",
    "        ax_loss.plot(epochs_range, history['val_loss'], marker='x', linestyle='--', label='Validation Loss')\n",
    "        ax_loss.set_title(f\"{name} Loss\")\n",
    "        ax_loss.set_xlabel('Epoch')\n",
    "        ax_loss.set_ylabel('Loss')\n",
    "        ax_loss.legend()\n",
    "        \n",
    "        fig_model.suptitle(f\"Accuracy and Loss Curves - {name}\", fontsize=16)\n",
    "        fig_model.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "        plt.savefig(os.path.join(run_dir, f\"{name}_training_curves.png\"))\n",
    "        plt.close(fig_model)\n",
    "    \n",
    "    # 4. Overall Performance Comparison Table\n",
    "    col_labels = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
    "    cell_text = []\n",
    "    for name in model_names:\n",
    "        perf = results[name]['performance']\n",
    "        row = [name,\n",
    "               f\"{perf['accuracy']:.4f}\",\n",
    "               f\"{perf['precision']:.4f}\",\n",
    "               f\"{perf['recall']:.4f}\",\n",
    "               f\"{perf['f1']:.4f}\"]\n",
    "        cell_text.append(row)\n",
    "    \n",
    "    fig_table, ax_table = plt.subplots(figsize=(8, len(model_names)*0.8+1))\n",
    "    ax_table.axis('tight')\n",
    "    ax_table.axis('off')\n",
    "    table = ax_table.table(cellText=cell_text, colLabels=col_labels, loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1, 2)\n",
    "    fig_table.suptitle(\"Overall Performance Comparison\", fontsize=16)\n",
    "    plt.savefig(os.path.join(run_dir, \"performance_table.png\"))\n",
    "    plt.close(fig_table)\n",
    "    \n",
    "    # 5. Save training histories to pickle files\n",
    "    for name in model_names:\n",
    "        history = results[name]['history']\n",
    "        with open(os.path.join(run_dir, f\"{name}_history.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(history, f)\n",
    "    print(\"Training histories saved for each model.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into train, validation, and test in 'D:/Learning/University of sadat/Grade 4/Semester 2/06- Graduation Project/Coding/00- The DataSet/Dataset_split_before_preprocess'.\n",
      "\n",
      "Training with VGG19...\n",
      "\n",
      "Found 41 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n",
      "Found 11 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 964ms/step - accuracy: 0.3704 - loss: 0.8432 - val_accuracy: 0.3333 - val_loss: 1.5608\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 939ms/step - accuracy: 0.5192 - loss: 0.7245 - val_accuracy: 0.3333 - val_loss: 1.1581\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 862ms/step - accuracy: 0.6195 - loss: 0.7991 - val_accuracy: 0.5000 - val_loss: 0.9208\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 846ms/step - accuracy: 0.6984 - loss: 0.5036 - val_accuracy: 0.6667 - val_loss: 0.8089\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 860ms/step - accuracy: 0.7505 - loss: 0.4571 - val_accuracy: 0.6667 - val_loss: 0.7167\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 888ms/step - accuracy: 0.6774 - loss: 0.5307 - val_accuracy: 0.6667 - val_loss: 0.6112\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 882ms/step - accuracy: 0.7648 - loss: 0.4743 - val_accuracy: 0.6667 - val_loss: 0.5322\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 881ms/step - accuracy: 0.8636 - loss: 0.3263 - val_accuracy: 0.8333 - val_loss: 0.4817\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 873ms/step - accuracy: 0.7873 - loss: 0.4329 - val_accuracy: 0.8333 - val_loss: 0.4239\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 880ms/step - accuracy: 0.9760 - loss: 0.2667 - val_accuracy: 0.8333 - val_loss: 0.3753\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 898ms/step - accuracy: 0.8883 - loss: 0.3461 - val_accuracy: 0.8333 - val_loss: 0.3275\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 989ms/step - accuracy: 0.8594 - loss: 0.2780 - val_accuracy: 1.0000 - val_loss: 0.2816\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 925ms/step - accuracy: 0.8981 - loss: 0.3109 - val_accuracy: 1.0000 - val_loss: 0.2357\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 986ms/step - accuracy: 0.8782 - loss: 0.2873 - val_accuracy: 1.0000 - val_loss: 0.2034\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 901ms/step - accuracy: 0.9738 - loss: 0.2017 - val_accuracy: 1.0000 - val_loss: 0.1820\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 875ms/step - accuracy: 0.9478 - loss: 0.2154 - val_accuracy: 1.0000 - val_loss: 0.1754\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 944ms/step - accuracy: 0.8845 - loss: 0.3760 - val_accuracy: 1.0000 - val_loss: 0.1667\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 895ms/step - accuracy: 0.9543 - loss: 0.2216 - val_accuracy: 1.0000 - val_loss: 0.1655\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9891 - loss: 0.0995 - val_accuracy: 1.0000 - val_loss: 0.1585\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 888ms/step - accuracy: 0.9877 - loss: 0.1318 - val_accuracy: 1.0000 - val_loss: 0.1521\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 593ms/step - accuracy: 1.0000 - loss: 0.0728\n",
      "\n",
      "VGG19 Test Loss: 0.0793\n",
      "VGG19 Test Accuracy: 1.0000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 656ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3 0]\n",
      " [0 8]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Oblique       1.00      1.00      1.00         3\n",
      "  Overriding       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "VGG19 model saved.\n",
      "Training histories saved for each model.\n",
      "\n",
      "Training with ResNet50...\n",
      "\n",
      "Found 41 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n",
      "Found 11 images belonging to 2 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Learning\\University of sadat\\Grade 4\\Semester 2\\06- Graduation Project\\Ai_Env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 669ms/step - accuracy: 0.4914 - loss: 0.8476 - val_accuracy: 0.5000 - val_loss: 0.7255\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 437ms/step - accuracy: 0.7228 - loss: 0.5925 - val_accuracy: 0.6667 - val_loss: 0.6417\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 418ms/step - accuracy: 0.7929 - loss: 0.4648 - val_accuracy: 0.8333 - val_loss: 0.5690\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 411ms/step - accuracy: 0.8763 - loss: 0.2917 - val_accuracy: 0.8333 - val_loss: 0.4991\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 421ms/step - accuracy: 0.8266 - loss: 0.3532 - val_accuracy: 0.8333 - val_loss: 0.4429\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 414ms/step - accuracy: 0.8784 - loss: 0.3239 - val_accuracy: 0.8333 - val_loss: 0.4028\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 416ms/step - accuracy: 0.8979 - loss: 0.2145 - val_accuracy: 0.8333 - val_loss: 0.3521\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 447ms/step - accuracy: 0.9077 - loss: 0.3246 - val_accuracy: 1.0000 - val_loss: 0.3190\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 412ms/step - accuracy: 0.9312 - loss: 0.2410 - val_accuracy: 1.0000 - val_loss: 0.2853\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 420ms/step - accuracy: 0.9729 - loss: 0.1735 - val_accuracy: 1.0000 - val_loss: 0.2574\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 415ms/step - accuracy: 0.9804 - loss: 0.1818 - val_accuracy: 1.0000 - val_loss: 0.2272\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 416ms/step - accuracy: 0.9388 - loss: 0.1789 - val_accuracy: 1.0000 - val_loss: 0.2096\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 412ms/step - accuracy: 0.9217 - loss: 0.2267 - val_accuracy: 1.0000 - val_loss: 0.1901\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 425ms/step - accuracy: 0.9249 - loss: 0.1782 - val_accuracy: 1.0000 - val_loss: 0.1685\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 409ms/step - accuracy: 0.9159 - loss: 0.1946 - val_accuracy: 1.0000 - val_loss: 0.1543\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 415ms/step - accuracy: 0.9443 - loss: 0.1783 - val_accuracy: 1.0000 - val_loss: 0.1418\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 401ms/step - accuracy: 0.9951 - loss: 0.0977 - val_accuracy: 1.0000 - val_loss: 0.1315\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 394ms/step - accuracy: 0.9608 - loss: 0.1243 - val_accuracy: 1.0000 - val_loss: 0.1284\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 398ms/step - accuracy: 0.9923 - loss: 0.1018 - val_accuracy: 1.0000 - val_loss: 0.1235\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 392ms/step - accuracy: 0.9743 - loss: 0.1002 - val_accuracy: 1.0000 - val_loss: 0.1160\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 0.0629\n",
      "\n",
      "ResNet50 Test Loss: 0.0690\n",
      "ResNet50 Test Accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000026EADF794E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000026EADF794E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 341ms/stepWARNING:tensorflow:6 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000026EADF794E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000026EADF794E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 931ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3 0]\n",
      " [0 8]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Oblique       1.00      1.00      1.00         3\n",
      "  Overriding       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "ResNet50 model saved.\n",
      "Training histories saved for each model.\n",
      "\n",
      "Training with VGG16...\n",
      "\n",
      "Found 41 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n",
      "Found 11 images belonging to 2 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Learning\\University of sadat\\Grade 4\\Semester 2\\06- Graduation Project\\Ai_Env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 743ms/step - accuracy: 0.5159 - loss: 0.8778 - val_accuracy: 0.3333 - val_loss: 1.0309\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 700ms/step - accuracy: 0.4653 - loss: 0.8029 - val_accuracy: 0.3333 - val_loss: 0.8591\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 692ms/step - accuracy: 0.6749 - loss: 0.5901 - val_accuracy: 0.5000 - val_loss: 0.6869\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 682ms/step - accuracy: 0.6765 - loss: 0.5731 - val_accuracy: 0.5000 - val_loss: 0.5326\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 715ms/step - accuracy: 0.5353 - loss: 0.7397 - val_accuracy: 0.5000 - val_loss: 0.4563\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 701ms/step - accuracy: 0.8038 - loss: 0.5555 - val_accuracy: 1.0000 - val_loss: 0.4225\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 686ms/step - accuracy: 0.7357 - loss: 0.5565 - val_accuracy: 1.0000 - val_loss: 0.3972\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 662ms/step - accuracy: 0.8256 - loss: 0.3779 - val_accuracy: 1.0000 - val_loss: 0.3887\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 667ms/step - accuracy: 0.8052 - loss: 0.4280 - val_accuracy: 1.0000 - val_loss: 0.3739\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 671ms/step - accuracy: 0.8832 - loss: 0.3069 - val_accuracy: 1.0000 - val_loss: 0.3563\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 667ms/step - accuracy: 0.9172 - loss: 0.3618 - val_accuracy: 1.0000 - val_loss: 0.3359\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 718ms/step - accuracy: 0.7797 - loss: 0.3538 - val_accuracy: 1.0000 - val_loss: 0.3061\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 689ms/step - accuracy: 0.8417 - loss: 0.3727 - val_accuracy: 1.0000 - val_loss: 0.2617\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 692ms/step - accuracy: 0.8470 - loss: 0.3260 - val_accuracy: 1.0000 - val_loss: 0.2372\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 694ms/step - accuracy: 0.9688 - loss: 0.2258 - val_accuracy: 1.0000 - val_loss: 0.2142\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 691ms/step - accuracy: 0.8965 - loss: 0.2964 - val_accuracy: 1.0000 - val_loss: 0.2047\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 704ms/step - accuracy: 0.8964 - loss: 0.2061 - val_accuracy: 1.0000 - val_loss: 0.1980\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 703ms/step - accuracy: 0.9472 - loss: 0.2396 - val_accuracy: 1.0000 - val_loss: 0.1878\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 687ms/step - accuracy: 0.9842 - loss: 0.1685 - val_accuracy: 1.0000 - val_loss: 0.1813\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 699ms/step - accuracy: 0.9376 - loss: 0.1497 - val_accuracy: 1.0000 - val_loss: 0.1749\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 487ms/step - accuracy: 1.0000 - loss: 0.0894\n",
      "\n",
      "VGG16 Test Loss: 0.0937\n",
      "VGG16 Test Accuracy: 1.0000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 529ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3 0]\n",
      " [0 8]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Oblique       1.00      1.00      1.00         3\n",
      "  Overriding       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "VGG16 model saved.\n",
      "Training histories saved for each model.\n",
      "\n",
      "Training with MobileNetV2...\n",
      "\n",
      "Found 41 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n",
      "Found 11 images belonging to 2 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Learning\\University of sadat\\Grade 4\\Semester 2\\06- Graduation Project\\Ai_Env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 377ms/step - accuracy: 0.6311 - loss: 0.6220 - val_accuracy: 0.6667 - val_loss: 0.6393\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - accuracy: 0.7355 - loss: 0.6707 - val_accuracy: 0.8333 - val_loss: 0.5677\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - accuracy: 0.8048 - loss: 0.4951 - val_accuracy: 1.0000 - val_loss: 0.4880\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 0.8772 - loss: 0.3265 - val_accuracy: 1.0000 - val_loss: 0.4315\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.9175 - loss: 0.3120 - val_accuracy: 1.0000 - val_loss: 0.3858\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.8309 - loss: 0.3569 - val_accuracy: 1.0000 - val_loss: 0.3521\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 0.9340 - loss: 0.2399 - val_accuracy: 1.0000 - val_loss: 0.3139\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.8903 - loss: 0.2434 - val_accuracy: 1.0000 - val_loss: 0.2701\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.8302 - loss: 0.3363 - val_accuracy: 1.0000 - val_loss: 0.2360\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - accuracy: 0.9165 - loss: 0.3025 - val_accuracy: 1.0000 - val_loss: 0.2151\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9267 - loss: 0.3221 - val_accuracy: 1.0000 - val_loss: 0.1976\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.9504 - loss: 0.2964 - val_accuracy: 1.0000 - val_loss: 0.1808\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.9480 - loss: 0.1848 - val_accuracy: 1.0000 - val_loss: 0.1574\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - accuracy: 0.9805 - loss: 0.1125 - val_accuracy: 1.0000 - val_loss: 0.1388\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.9401 - loss: 0.2027 - val_accuracy: 1.0000 - val_loss: 0.1283\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.9923 - loss: 0.0930 - val_accuracy: 1.0000 - val_loss: 0.1198\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.9475 - loss: 0.1403 - val_accuracy: 1.0000 - val_loss: 0.1079\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 0.1092 - val_accuracy: 1.0000 - val_loss: 0.0961\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - accuracy: 0.9951 - loss: 0.0600 - val_accuracy: 1.0000 - val_loss: 0.0849\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - accuracy: 0.9457 - loss: 0.2564 - val_accuracy: 1.0000 - val_loss: 0.0819\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0494 \n",
      "\n",
      "MobileNetV2 Test Loss: 0.0534\n",
      "MobileNetV2 Test Accuracy: 1.0000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 557ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3 0]\n",
      " [0 8]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Oblique       1.00      1.00      1.00         3\n",
      "  Overriding       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "MobileNetV2 model saved.\n",
      "Training histories saved for each model.\n",
      "\n",
      "Training with Xception...\n",
      "\n",
      "Found 41 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n",
      "Found 11 images belonging to 2 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Learning\\University of sadat\\Grade 4\\Semester 2\\06- Graduation Project\\Ai_Env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 962ms/step - accuracy: 0.6108 - loss: 0.6103 - val_accuracy: 1.0000 - val_loss: 0.6370\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 746ms/step - accuracy: 0.7558 - loss: 0.5625 - val_accuracy: 0.8333 - val_loss: 0.6208\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 740ms/step - accuracy: 0.8000 - loss: 0.4995 - val_accuracy: 0.8333 - val_loss: 0.6143\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 798ms/step - accuracy: 0.8502 - loss: 0.3589 - val_accuracy: 0.8333 - val_loss: 0.6051\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 879ms/step - accuracy: 0.6792 - loss: 0.5850 - val_accuracy: 0.8333 - val_loss: 0.5817\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 818ms/step - accuracy: 0.8507 - loss: 0.3937 - val_accuracy: 1.0000 - val_loss: 0.5645\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 777ms/step - accuracy: 0.7614 - loss: 0.4483 - val_accuracy: 0.8333 - val_loss: 0.5475\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 984ms/step - accuracy: 0.9729 - loss: 0.2776 - val_accuracy: 0.8333 - val_loss: 0.5303\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8500 - loss: 0.3943 - val_accuracy: 1.0000 - val_loss: 0.5043\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.9608 - loss: 0.2057 - val_accuracy: 1.0000 - val_loss: 0.4909\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.9248 - loss: 0.2156 - val_accuracy: 1.0000 - val_loss: 0.4790\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 825ms/step - accuracy: 0.9676 - loss: 0.2095 - val_accuracy: 1.0000 - val_loss: 0.4650\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 839ms/step - accuracy: 0.7921 - loss: 0.2591 - val_accuracy: 1.0000 - val_loss: 0.4381\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 764ms/step - accuracy: 0.9338 - loss: 0.1940 - val_accuracy: 1.0000 - val_loss: 0.4124\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 764ms/step - accuracy: 0.9923 - loss: 0.1270 - val_accuracy: 1.0000 - val_loss: 0.3950\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 754ms/step - accuracy: 0.9926 - loss: 0.1118 - val_accuracy: 1.0000 - val_loss: 0.3764\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 795ms/step - accuracy: 0.9665 - loss: 0.1207 - val_accuracy: 1.0000 - val_loss: 0.3599\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 801ms/step - accuracy: 0.9612 - loss: 0.1549 - val_accuracy: 1.0000 - val_loss: 0.3423\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 800ms/step - accuracy: 0.9923 - loss: 0.0826 - val_accuracy: 1.0000 - val_loss: 0.3294\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 794ms/step - accuracy: 0.9427 - loss: 0.1269 - val_accuracy: 1.0000 - val_loss: 0.3129\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 1.0000 - loss: 0.2723\n",
      "\n",
      "Xception Test Loss: 0.2715\n",
      "Xception Test Accuracy: 1.0000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 833ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3 0]\n",
      " [0 8]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Oblique       1.00      1.00      1.00         3\n",
      "  Overriding       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "Xception model saved.\n",
      "Training histories saved for each model.\n",
      "\n",
      "Training with EfficientNetB0...\n",
      "\n",
      "Found 41 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n",
      "Found 11 images belonging to 2 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Learning\\University of sadat\\Grade 4\\Semester 2\\06- Graduation Project\\Ai_Env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 548ms/step - accuracy: 0.5203 - loss: 0.6848 - val_accuracy: 0.6667 - val_loss: 0.6442\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - accuracy: 0.6129 - loss: 0.7716 - val_accuracy: 0.8333 - val_loss: 0.6071\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - accuracy: 0.7012 - loss: 0.5102 - val_accuracy: 0.8333 - val_loss: 0.5776\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - accuracy: 0.6874 - loss: 0.5420 - val_accuracy: 1.0000 - val_loss: 0.5446\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - accuracy: 0.7163 - loss: 0.5606 - val_accuracy: 1.0000 - val_loss: 0.5080\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - accuracy: 0.8707 - loss: 0.3940 - val_accuracy: 1.0000 - val_loss: 0.4728\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - accuracy: 0.6815 - loss: 0.4844 - val_accuracy: 1.0000 - val_loss: 0.4342\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - accuracy: 0.8625 - loss: 0.4078 - val_accuracy: 1.0000 - val_loss: 0.4020\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - accuracy: 0.8441 - loss: 0.3365 - val_accuracy: 1.0000 - val_loss: 0.3725\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - accuracy: 0.9574 - loss: 0.2157 - val_accuracy: 1.0000 - val_loss: 0.3450\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - accuracy: 0.9403 - loss: 0.2340 - val_accuracy: 1.0000 - val_loss: 0.3194\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - accuracy: 0.9591 - loss: 0.2105 - val_accuracy: 1.0000 - val_loss: 0.2961\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - accuracy: 0.8947 - loss: 0.2480 - val_accuracy: 1.0000 - val_loss: 0.2695\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - accuracy: 0.8360 - loss: 0.2126 - val_accuracy: 1.0000 - val_loss: 0.2466\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - accuracy: 0.8405 - loss: 0.3153 - val_accuracy: 1.0000 - val_loss: 0.2235\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - accuracy: 0.9409 - loss: 0.1626 - val_accuracy: 1.0000 - val_loss: 0.2066\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - accuracy: 0.9408 - loss: 0.1779 - val_accuracy: 1.0000 - val_loss: 0.1874\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 0.1469 - val_accuracy: 1.0000 - val_loss: 0.1690\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - accuracy: 0.8485 - loss: 0.1860 - val_accuracy: 1.0000 - val_loss: 0.1536\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 0.9818 - loss: 0.1283 - val_accuracy: 1.0000 - val_loss: 0.1393\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.1176 \n",
      "\n",
      "EfficientNetB0 Test Loss: 0.1159\n",
      "EfficientNetB0 Test Accuracy: 1.0000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 959ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3 0]\n",
      " [0 8]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Oblique       1.00      1.00      1.00         3\n",
      "  Overriding       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "EfficientNetB0 model saved.\n",
      "Training histories saved for each model.\n",
      "\n",
      "Training with DenseNet121...\n",
      "\n",
      "Found 41 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n",
      "Found 11 images belonging to 2 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Learning\\University of sadat\\Grade 4\\Semester 2\\06- Graduation Project\\Ai_Env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 850ms/step - accuracy: 0.6248 - loss: 0.7300 - val_accuracy: 0.3333 - val_loss: 0.7093\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380ms/step - accuracy: 0.7259 - loss: 0.5800 - val_accuracy: 0.5000 - val_loss: 0.6656\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - accuracy: 0.5412 - loss: 0.6868 - val_accuracy: 0.5000 - val_loss: 0.6240\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377ms/step - accuracy: 0.6651 - loss: 0.5226 - val_accuracy: 0.5000 - val_loss: 0.5915\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - accuracy: 0.7340 - loss: 0.4768 - val_accuracy: 0.6667 - val_loss: 0.5616\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - accuracy: 0.9133 - loss: 0.3528 - val_accuracy: 0.6667 - val_loss: 0.5252\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - accuracy: 0.8177 - loss: 0.3831 - val_accuracy: 0.6667 - val_loss: 0.4890\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - accuracy: 0.9014 - loss: 0.2879 - val_accuracy: 0.6667 - val_loss: 0.4666\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - accuracy: 0.8743 - loss: 0.3347 - val_accuracy: 0.6667 - val_loss: 0.4460\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 381ms/step - accuracy: 0.9511 - loss: 0.2541 - val_accuracy: 0.6667 - val_loss: 0.4145\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 422ms/step - accuracy: 0.8889 - loss: 0.2660 - val_accuracy: 0.8333 - val_loss: 0.3915\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 405ms/step - accuracy: 0.9217 - loss: 0.2728 - val_accuracy: 0.8333 - val_loss: 0.3718\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 388ms/step - accuracy: 0.8770 - loss: 0.2778 - val_accuracy: 0.8333 - val_loss: 0.3597\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 390ms/step - accuracy: 0.9451 - loss: 0.2558 - val_accuracy: 0.8333 - val_loss: 0.3447\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 390ms/step - accuracy: 0.9285 - loss: 0.2130 - val_accuracy: 0.8333 - val_loss: 0.3432\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 400ms/step - accuracy: 1.0000 - loss: 0.1661 - val_accuracy: 0.8333 - val_loss: 0.3418\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 406ms/step - accuracy: 0.9057 - loss: 0.2233 - val_accuracy: 0.8333 - val_loss: 0.3283\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 412ms/step - accuracy: 0.9891 - loss: 0.1559 - val_accuracy: 0.8333 - val_loss: 0.3234\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 462ms/step - accuracy: 0.9951 - loss: 0.1039 - val_accuracy: 0.8333 - val_loss: 0.3132\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 392ms/step - accuracy: 0.9319 - loss: 0.2238 - val_accuracy: 0.8333 - val_loss: 0.3126\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235ms/step - accuracy: 0.9295 - loss: 0.1826\n",
      "\n",
      "DenseNet121 Test Loss: 0.2082\n",
      "DenseNet121 Test Accuracy: 0.9091\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3 0]\n",
      " [1 7]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Oblique       0.75      1.00      0.86         3\n",
      "  Overriding       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.91        11\n",
      "   macro avg       0.88      0.94      0.90        11\n",
      "weighted avg       0.93      0.91      0.91        11\n",
      "\n",
      "DenseNet121 model saved.\n",
      "Training histories saved for each model.\n",
      "All outputs saved to directory: D:/Learning/University of sadat/Grade 4/Semester 2/06- Graduation Project/Coding/runs_codes\\before_preprocess_2025-04-21_00-29-45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    ##### # Paths to dataset directory\n",
    "    Base_Folder = 'D:/Learning/University of sadat/Grade 4/Semester 2/06- Graduation Project/Coding/' \n",
    "    original_dataset_dir = f'{Base_Folder}00- The DataSet/00- Dogs Femur Fracture'\n",
    "    split_dataset_dir = f'{Base_Folder}00- The DataSet/Dataset_split_before_preprocess'\n",
    "    ##### # Split the dataset to train, validation and testing \n",
    "    # split_dataset(original_dataset_dir, split_dataset_dir, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1)\n",
    "    \n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    run_dir = os.path.join(f'{Base_Folder}runs_codes', f\"before_preprocess_{current_time}\")\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    ################################ Save the Jupiter Note Book in the runs code \n",
    "    # Get the current notebook's path\n",
    "    def get_notebook_path():\n",
    "        ipython = get_ipython()\n",
    "        if ipython is None:\n",
    "            raise RuntimeError(\"Not running in Jupyter.\")\n",
    "        # VS Code specific (may not work in all environments)\n",
    "        if '__vsc_ipynb_file__' in ipython.user_ns:\n",
    "            return Path(ipython.user_ns['__vsc_ipynb_file__'])\n",
    "        # Fallback or other environments\n",
    "        try:\n",
    "            return Path(ipython.startup_scripts[0])\n",
    "        except:\n",
    "            raise RuntimeError(\"Could not determine notebook path.\")\n",
    "\n",
    "\n",
    "    # Get the current notebook's path and name\n",
    "    notebook_path = get_notebook_path()\n",
    "    notebook_name = notebook_path.name\n",
    "    # Create the destination path\n",
    "    destination_path = os.path.join(run_dir, notebook_name)\n",
    "\n",
    "    # Copy the notebook to the specified directory\n",
    "    shutil.copy(notebook_path, destination_path)\n",
    "    #########################################################################\n",
    "    batch_size = 5\n",
    "    epochs = 20\n",
    "    \n",
    "    results = {}\n",
    "    models = {\n",
    "        'VGG19': vgg19_preprocess,\n",
    "        'ResNet50': resnet50_preprocess,\n",
    "        'VGG16': vgg16_preprocess,\n",
    "        'MobileNetV2': mobilenetv2_preprocess,\n",
    "        'Xception': xception_preprocess,\n",
    "        'EfficientNetB0': efficientnetb0_preprocess,\n",
    "        'DenseNet121': densenet121_preprocess\n",
    "    }\n",
    "    \n",
    "    for model_name, preprocess in models.items():\n",
    "        results[model_name] = train_and_evaluate_model(model_name, preprocess)\n",
    "        \n",
    "        model_path = os.path.join(run_dir, f\"{model_name}_results.pkl\")\n",
    "        results[model_name]['model'].save(f\"{run_dir}/{model_name}_model.h5\")\n",
    "        print(f\"{model_name} model saved.\")\n",
    "        plot_results(results,run_dir)\n",
    "    \n",
    "    print(f\"All outputs saved to directory: {run_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ai_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
