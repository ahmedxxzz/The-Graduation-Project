{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from IPython.core.getipython import get_ipython\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19, ResNet50, VGG16, MobileNetV2, Xception, EfficientNetB0, DenseNet121\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg19_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenetv2_preprocess\n",
    "from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnetb0_preprocess\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet121_preprocess\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout,Dense, BatchNormalization,Activation, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report, f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(generator, model, steps):\n",
    "    \"\"\"\n",
    "    Extract features from a dataset using a feature extractor model.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    for _ in range(steps):\n",
    "        batch_x, batch_y = next(generator)\n",
    "        batch_features = model.predict(batch_x, verbose=0)\n",
    "        features.append(batch_features)\n",
    "        labels.append(batch_y)\n",
    "    features = np.vstack(features)[:generator.samples]  \n",
    "    labels = np.hstack(labels)[:generator.samples]\n",
    "    return features, labels\n",
    "\n",
    "def train_and_evaluate_model(model_name, preprocess_function):\n",
    "    print(f\"\\nTraining with {model_name}...\\n\")\n",
    "    \n",
    "    # Set image size based on model\n",
    "    if model_name == 'Xception':\n",
    "        img_h, img_w = 299, 299\n",
    "    else:\n",
    "        img_h, img_w = 224, 224\n",
    "\n",
    "    \n",
    "    # Create ImageDataGenerators , to load and preprocess images\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_function)\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_function)\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_function)\n",
    "    \n",
    "    train_dir = os.path.join(split_dataset_dir, \"train\")\n",
    "    val_dir = os.path.join(split_dataset_dir, \"validation\")\n",
    "    test_dir = os.path.join(split_dataset_dir, \"test\")\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(train_dir,target_size=(img_h, img_w),batch_size=batch_size,class_mode='binary',shuffle=True,seed=42,)\n",
    "    val_generator = val_datagen.flow_from_directory(val_dir,target_size=(img_h, img_w),batch_size=batch_size,class_mode='binary',shuffle=False,seed=42,)    \n",
    "    test_generator = test_datagen.flow_from_directory(test_dir,target_size=(img_h, img_w),batch_size=batch_size,class_mode='binary',shuffle=False,seed=42,)\n",
    "    \n",
    "    class_indices = test_generator.class_indices    \n",
    "    print(f\"class indices: {list(class_indices.keys())}\")    \n",
    "    # Load the pre-trained model\n",
    "    if model_name == 'VGG19':\n",
    "        Pretrained_model = VGG19(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'ResNet50':\n",
    "        Pretrained_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'VGG16':\n",
    "        Pretrained_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'MobileNetV2':\n",
    "        Pretrained_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'Xception':\n",
    "        Pretrained_model = Xception(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'EfficientNetB0':\n",
    "        Pretrained_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'DenseNet121':\n",
    "        Pretrained_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "    \n",
    "    # Freeze the pre-trained layers\n",
    "    Pretrained_model.trainable = False\n",
    "    \n",
    "    # Create feature extractor including GlobalAveragePooling2D\n",
    "    feature_extractor = Model(inputs=Pretrained_model.input,outputs=GlobalAveragePooling2D()(Pretrained_model.output))\n",
    "    \n",
    "    # Calculate steps for feature extraction\n",
    "    train_steps = math.ceil(train_generator.samples / batch_size)\n",
    "    val_steps = math.ceil(val_generator.samples / batch_size)\n",
    "    test_steps = math.ceil(test_generator.samples / batch_size)\n",
    "    \n",
    "    # Extract features\n",
    "    print(\"Extracting features for training set...\")\n",
    "    train_features, train_labels = extract_features(train_generator, feature_extractor, train_steps)\n",
    "    print(\"Extracting features for validation set...\")\n",
    "    val_features, val_labels = extract_features(val_generator, feature_extractor, val_steps)\n",
    "    print(\"Extracting features for test set...\")\n",
    "    test_features, test_labels = extract_features(test_generator, feature_extractor, test_steps)\n",
    "\n",
    "    # Define simplified custom head\n",
    "    feature_dim = feature_extractor.output_shape[-1]  # e.g., 512 for VGG16\n",
    "    input_layer = Input(shape=(feature_dim,))\n",
    "    x = Dense(512)(input_layer)  # Reduced from two layers\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    predictions = Dense(1, activation='sigmoid', dtype='float32')(x)\n",
    "    custom_model = Model(inputs=input_layer, outputs=predictions)\n",
    "    \n",
    "    # Compile the custom head model\n",
    "    custom_model.compile(optimizer=Adam(learning_rate=1e-4),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # Early stopping with potentially reduced patience\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    # Train the custom head on extracted features\n",
    "    history = custom_model.fit(train_features, train_labels,batch_size=batch_size,epochs=epochs,validation_data=(val_features, val_labels),callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss, test_accuracy = custom_model.evaluate(test_features, test_labels, verbose=1)\n",
    "    print(f\"\\n{model_name} Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"{model_name} Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = custom_model.predict(test_features, verbose=1)\n",
    "    y_pred = (predictions > 0.5).astype(int).flatten()\n",
    "    y_true = test_labels  # Use extracted labels\n",
    "    \n",
    "    # Compute performance metrics\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    \n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "    precision = precision_score(y_true, y_pred, average='binary')\n",
    "    recall = recall_score(y_true, y_pred, average='binary')\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    labels = list(class_indices.keys())\n",
    "    print(classification_report(y_true, y_pred, target_names=labels))\n",
    "    \n",
    "    # Compute ROC Curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, predictions.flatten())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return {\n",
    "        'model': custom_model,\n",
    "        'history': history.history,\n",
    "        'confusion_matrix': cm,\n",
    "        'roc': (fpr, tpr, roc_auc),\n",
    "        'performance': {'accuracy': test_accuracy, 'f1': f1, 'precision': precision, 'recall': recall},\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "def plot_results(results, run_dir):\n",
    "    model_names = list(results.keys())\n",
    "    num_models = len(model_names)\n",
    "    \n",
    "    # 1. Plot Confusion Matrices\n",
    "    fig_cm, axes_cm = plt.subplots(1, num_models, figsize=(5*num_models, 4))\n",
    "    if num_models == 1:\n",
    "        axes_cm = [axes_cm]\n",
    "    for ax, name in zip(axes_cm, model_names):\n",
    "        cm = results[name]['confusion_matrix']\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        ax.set_title(f\"{name} Confusion Matrix\")\n",
    "        tick_marks = np.arange(len(results[name]['labels']))\n",
    "        ax.set_xticks(tick_marks)\n",
    "        ax.set_xticklabels(results[name]['labels'], rotation=45)\n",
    "        ax.set_yticks(tick_marks)\n",
    "        ax.set_yticklabels(results[name]['labels'])\n",
    "        thresh = cm.max() / 2.0\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        fig_cm.colorbar(im, ax=ax)\n",
    "    fig_cm.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig_cm.suptitle(\"Confusion Matrices\", fontsize=16)\n",
    "    plt.savefig(os.path.join(run_dir, \"confusion_matrices.png\"))\n",
    "    plt.close(fig_cm)\n",
    "    \n",
    "    # 2. Plot ROC Curves\n",
    "    fig_roc, axes_roc = plt.subplots(1, num_models, figsize=(5*num_models, 4))\n",
    "    if num_models == 1:\n",
    "        axes_roc = [axes_roc]\n",
    "    for ax, name in zip(axes_roc, model_names):\n",
    "        fpr, tpr, roc_auc = results[name]['roc']\n",
    "        ax.plot(fpr, tpr, lw=2, label=f\"AUC = {roc_auc:.2f}\")\n",
    "        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title(f\"ROC Curve - {name}\")\n",
    "        ax.legend(loc=\"lower right\")\n",
    "    fig_roc.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig_roc.suptitle(\"ROC Curves\", fontsize=16)\n",
    "    plt.savefig(os.path.join(run_dir, \"roc_curves.png\"))\n",
    "    plt.close(fig_roc)\n",
    "    \n",
    "    # 3. Plot Accuracy and Loss Curves for each model\n",
    "    for name in model_names:\n",
    "        history = results[name]['history']\n",
    "        epochs_range = range(1, len(history['accuracy']) + 1)\n",
    "        fig_model, (ax_acc, ax_loss) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        ax_acc.plot(epochs_range, history['accuracy'], marker='o', label='Train Accuracy')\n",
    "        ax_acc.plot(epochs_range, history['val_accuracy'], marker='x', linestyle='--', label='Validation Accuracy')\n",
    "        ax_acc.set_title(f\"{name} Accuracy\")\n",
    "        ax_acc.set_xlabel('Epoch')\n",
    "        ax_acc.set_ylabel('Accuracy')\n",
    "        ax_acc.legend()\n",
    "        \n",
    "        ax_loss.plot(epochs_range, history['loss'], marker='o', label='Train Loss')\n",
    "        ax_loss.plot(epochs_range, history['val_loss'], marker='x', linestyle='--', label='Validation Loss')\n",
    "        ax_loss.set_title(f\"{name} Loss\")\n",
    "        ax_loss.set_xlabel('Epoch')\n",
    "        ax_loss.set_ylabel('Loss')\n",
    "        ax_loss.legend()\n",
    "        \n",
    "        fig_model.suptitle(f\"Accuracy and Loss Curves - {name}\", fontsize=16)\n",
    "        fig_model.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "        plt.savefig(os.path.join(run_dir, f\"{name}_training_curves.png\"))\n",
    "        plt.close(fig_model)\n",
    "    \n",
    "    # 4. Overall Performance Comparison Table\n",
    "    col_labels = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
    "    cell_text = []\n",
    "    for name in model_names:\n",
    "        perf = results[name]['performance']\n",
    "        row = [name,\n",
    "               f\"{perf['accuracy']:.4f}\",\n",
    "               f\"{perf['precision']:.4f}\",\n",
    "               f\"{perf['recall']:.4f}\",\n",
    "               f\"{perf['f1']:.4f}\"]\n",
    "        cell_text.append(row)\n",
    "    \n",
    "    fig_table, ax_table = plt.subplots(figsize=(8, len(model_names)*0.8+1))\n",
    "    ax_table.axis('tight')\n",
    "    ax_table.axis('off')\n",
    "    table = ax_table.table(cellText=cell_text, colLabels=col_labels, loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1, 2)\n",
    "    fig_table.suptitle(\"Overall Performance Comparison\", fontsize=16)\n",
    "    plt.savefig(os.path.join(run_dir, \"performance_table.png\"))\n",
    "    plt.close(fig_table)\n",
    "    \n",
    "    # 5. Save training histories to pickle files\n",
    "    for name in model_names:\n",
    "        history = results[name]['history']\n",
    "        with open(os.path.join(run_dir, f\"{name}_history.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(history, f)\n",
    "    print(\"Training histories saved for each model.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with ResNet50...\n",
      "\n",
      "Found 6784 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "class indices: ['Oblique', 'Overriding']\n",
      "Extracting features for training set...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 53\u001b[0m\n\u001b[0;32m     42\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# 'VGG19': vgg19_preprocess,\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResNet50\u001b[39m\u001b[38;5;124m'\u001b[39m: resnet50_preprocess,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# 'DenseNet121': densenet121_preprocess\u001b[39;00m\n\u001b[0;32m     50\u001b[0m }\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, preprocess \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 53\u001b[0m     results[model_name] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# Save the custom head model instead\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     results[model_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_custom_head_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[1;32mIn[6], line 72\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[1;34m(model_name, preprocess_function)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting features for training set...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m train_features, train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting features for validation set...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     74\u001b[0m val_features, val_labels \u001b[38;5;241m=\u001b[39m extract_features(val_generator, feature_extractor, val_steps)\n",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(generator, model, steps)\u001b[0m\n\u001b[0;32m      6\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[1;32m----> 8\u001b[0m     batch_x, batch_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     batch_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(batch_x, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     10\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(batch_features)\n",
      "File \u001b[1;32md:\\Learning\\University of sadat\\Grade 4\\Semester 2\\06- Graduation Project\\Ai_Env\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:112\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m     index_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_generator)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# so it can be done in parallel\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Learning\\University of sadat\\Grade 4\\Semester 2\\06- Graduation Project\\Ai_Env\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:313\u001b[0m, in \u001b[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    311\u001b[0m filepaths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepaths\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(index_array):\n\u001b[1;32m--> 313\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mimage_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepaths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     x \u001b[38;5;241m=\u001b[39m image_utils\u001b[38;5;241m.\u001b[39mimg_to_array(img, data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format)\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;66;03m# Pillow images should be closed after `load_img`,\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;66;03m# but not PIL images.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Learning\\University of sadat\\Grade 4\\Semester 2\\06- Graduation Project\\Ai_Env\\Lib\\site-packages\\keras\\src\\utils\\image_utils.py:236\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    234\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 236\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath should be path-like or io.BytesIO, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Update the main execution block to use the new function as is\n",
    "if __name__ == \"__main__\":\n",
    "    Base_Folder = 'D:/Learning/University of sadat/Grade 4/Semester 2/06- Graduation Project/Coding/' \n",
    "    original_dataset_dir = f'{Base_Folder}00- The DataSet/Balanced_DataSet'\n",
    "    split_dataset_dir = f'{Base_Folder}00- The DataSet/Dataset_split'\n",
    "    \n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    run_dir = os.path.join(f'{Base_Folder}runs_codes', current_time)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    # # Copy current script to run directory\n",
    "    # script_path = os.path.abspath(__file__)\n",
    "    # script_name = os.path.basename(script_path)\n",
    "    # shutil.copy(script_path, os.path.join(run_dir, script_name))\n",
    "    def get_notebook_path():\n",
    "        ipython = get_ipython()\n",
    "        if ipython is None:\n",
    "            raise RuntimeError(\"Not running in Jupyter.\")\n",
    "        # VS Code specific (may not work in all environments)\n",
    "        if '__vsc_ipynb_file__' in ipython.user_ns:\n",
    "            return Path(ipython.user_ns['__vsc_ipynb_file__'])\n",
    "        # Fallback or other environments\n",
    "        try:\n",
    "            return Path(ipython.startup_scripts[0])\n",
    "        except:\n",
    "            raise RuntimeError(\"Could not determine notebook path.\")\n",
    "\n",
    "    notebook_path = get_notebook_path()\n",
    "    notebook_name = notebook_path.name\n",
    "    # Create the destination path\n",
    "    destination_path = os.path.join(run_dir, notebook_name)\n",
    "\n",
    "    # Copy the notebook to the specified directory\n",
    "    shutil.copy(notebook_path, destination_path)\n",
    "    \n",
    "    batch_size = 32  \n",
    "    epochs = 50\n",
    "    \n",
    "    results = {}\n",
    "    models = {\n",
    "        'VGG19': vgg19_preprocess,\n",
    "        'ResNet50': resnet50_preprocess,\n",
    "        'VGG16': vgg16_preprocess,\n",
    "        'MobileNetV2': mobilenetv2_preprocess,\n",
    "        'Xception': xception_preprocess,\n",
    "        'EfficientNetB0': efficientnetb0_preprocess,\n",
    "        'DenseNet121': densenet121_preprocess\n",
    "    }\n",
    "    \n",
    "    for model_name, preprocess in models.items():\n",
    "        results[model_name] = train_and_evaluate_model(model_name, preprocess)\n",
    "        \n",
    "        # Save the custom head model instead\n",
    "        results[model_name]['model'].save(os.path.join(run_dir, f\"{model_name}_custom_model.h5\"))\n",
    "        print(f\"{model_name} custom head model saved.\")\n",
    "    \n",
    "        plot_results(results, run_dir)\n",
    "    print(f\"All outputs saved to directory: {run_dir}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ai_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
