{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Registering two statistical functions with name 'AddV2,flops'! (Previous registration was in register d:\\\\Learning\\\\University of sadat\\\\Grade 4\\\\Semester 2\\\\06- Graduation Project\\\\Ai_Env\\\\Lib\\\\site-packages\\\\tensorflow\\\\python\\\\framework\\\\registry.py:65)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpsutil\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_flops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_flops \n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n",
      "File \u001b[1;32md:\\Learning\\University of sadat\\Grade 4\\Semester 2\\06- Graduation Project\\Ai_Env\\Lib\\site-packages\\keras_flops\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflops_calculation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_flops\n",
      "File \u001b[1;32md:\\Learning\\University of sadat\\Grade 4\\Semester 2\\06- Graduation Project\\Ai_Env\\Lib\\site-packages\\keras_flops\\flops_calculation.py:9\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvert_to_constants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     convert_variables_to_constants_v2_as_graph,\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential, Model\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras_flops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflops_registory\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_flops\u001b[39m(model: Union[Model, Sequential], batch_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    Calculate FLOPS for tf.keras.Model or tf.keras.Sequential .\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    Ignore operations used in only training mode such as Initialization.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    Use tf.profiler of tensorflow v1 api.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32md:\\Learning\\University of sadat\\Grade 4\\Semester 2\\06- Graduation Project\\Ai_Env\\Lib\\site-packages\\keras_flops\\flops_registory.py:38\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# reduction - comparison, no finalization\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reduction_op_flops(graph, node, reduce_flops\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, finalize_flops\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;129;43m@ops\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRegisterStatistics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAddV2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflops\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m_flops_add\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"inference is supportted\"\"\"\u001b[39;49;00m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_binary_per_element_op_flops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Learning\\University of sadat\\Grade 4\\Semester 2\\06- Graduation Project\\Ai_Env\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1896\u001b[0m, in \u001b[0;36mRegisterStatistics.__call__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   1894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, f: _T) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[0;32m   1895\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Registers \"f\" as the statistics function for \"op_type\".\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1896\u001b[0m   \u001b[43m_stats_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statistic_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1897\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32md:\\Learning\\University of sadat\\Grade 4\\Semester 2\\06- Graduation Project\\Ai_Env\\Lib\\site-packages\\tensorflow\\python\\framework\\registry.py:57\u001b[0m, in \u001b[0;36mRegistry.register\u001b[1;34m(self, candidate, name)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry:\n\u001b[0;32m     56\u001b[0m   frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry[name][_LOCATION_TAG]\n\u001b[1;32m---> 57\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegistering two \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Previous registration was in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m     60\u001b[0m       (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, name, frame\u001b[38;5;241m.\u001b[39mname, frame\u001b[38;5;241m.\u001b[39mfilename, frame\u001b[38;5;241m.\u001b[39mlineno))\n\u001b[0;32m     62\u001b[0m logging\u001b[38;5;241m.\u001b[39mvlog(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegistering \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, candidate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# stack trace is [this_function, Register(), user_function,...]\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# so the user function is #2.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Registering two statistical functions with name 'AddV2,flops'! (Previous registration was in register d:\\\\Learning\\\\University of sadat\\\\Grade 4\\\\Semester 2\\\\06- Graduation Project\\\\Ai_Env\\\\Lib\\\\site-packages\\\\tensorflow\\\\python\\\\framework\\\\registry.py:65)\""
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "from keras_flops import get_flops \n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from IPython.core.getipython import get_ipython\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19, ResNet50, VGG16, MobileNetV2, Xception, EfficientNetB0, DenseNet121\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg19_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenetv2_preprocess\n",
    "from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnetb0_preprocess\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet121_preprocess\n",
    "\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout,Dense, BatchNormalization,Activation, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report, f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(generator, model, steps):\n",
    "    \"\"\"\n",
    "    Extract features from a dataset using a feature extractor model.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    for _ in range(steps):\n",
    "        batch_x, batch_y = next(generator)\n",
    "        batch_features = model.predict(batch_x, verbose=0)\n",
    "        features.append(batch_features)\n",
    "        labels.append(batch_y)\n",
    "    features = np.vstack(features)[:generator.samples]  \n",
    "    labels = np.hstack(labels)[:generator.samples]\n",
    "    return features, labels\n",
    "\n",
    "def train_and_evaluate_model(model_name, preprocess_function):\n",
    "    print(f\"\\nTraining with {model_name}...\\n\")\n",
    "    \n",
    "    # Set image size based on model\n",
    "    if model_name == 'Xception':\n",
    "        img_h, img_w = 299, 299\n",
    "    else:\n",
    "        img_h, img_w = 224, 224\n",
    "\n",
    "    \n",
    "    # Create ImageDataGenerators , to load and preprocess images\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_function)\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_function)\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_function)\n",
    "    \n",
    "    train_dir = os.path.join(split_dataset_dir, \"train\")\n",
    "    val_dir = os.path.join(split_dataset_dir, \"validation\")\n",
    "    test_dir = os.path.join(split_dataset_dir, \"test\")\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(train_dir,target_size=(img_h, img_w),batch_size=batch_size,class_mode='binary',shuffle=True,seed=42,)\n",
    "    val_generator = val_datagen.flow_from_directory(val_dir,target_size=(img_h, img_w),batch_size=batch_size,class_mode='binary',shuffle=False,seed=42,)    \n",
    "    test_generator = test_datagen.flow_from_directory(test_dir,target_size=(img_h, img_w),batch_size=batch_size,class_mode='binary',shuffle=False,seed=42,)\n",
    "    \n",
    "    class_indices = test_generator.class_indices    \n",
    "    print(f\"class indices: {list(class_indices.keys())}\")    \n",
    "    # Load the pre-trained model\n",
    "    if model_name == 'VGG19':\n",
    "        Pretrained_model = VGG19(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'ResNet50':\n",
    "        Pretrained_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'VGG16':\n",
    "        Pretrained_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'MobileNetV2':\n",
    "        Pretrained_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'Xception':\n",
    "        Pretrained_model = Xception(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'EfficientNetB0':\n",
    "        Pretrained_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    elif model_name == 'DenseNet121':\n",
    "        Pretrained_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "    \n",
    "    # Freeze the pre-trained layers\n",
    "    Pretrained_model.trainable = False\n",
    "    \n",
    "    # Create feature extractor including GlobalAveragePooling2D\n",
    "    feature_extractor = Model(inputs=Pretrained_model.input,outputs=GlobalAveragePooling2D()(Pretrained_model.output))\n",
    "    \n",
    "    # Calculate steps for feature extraction\n",
    "    train_steps = math.ceil(train_generator.samples / batch_size)\n",
    "    val_steps = math.ceil(val_generator.samples / batch_size)\n",
    "    test_steps = math.ceil(test_generator.samples / batch_size)\n",
    "    \n",
    "    # Extract features\n",
    "    print(\"Extracting features for training set...\")\n",
    "    train_features, train_labels = extract_features(train_generator, feature_extractor, train_steps)\n",
    "    print(\"Extracting features for validation set...\")\n",
    "    val_features, val_labels = extract_features(val_generator, feature_extractor, val_steps)\n",
    "    print(\"Extracting features for test set...\")\n",
    "    test_features, test_labels = extract_features(test_generator, feature_extractor, test_steps)\n",
    "\n",
    "    # Define simplified custom head\n",
    "    feature_dim = feature_extractor.output_shape[-1]  # e.g., 512 for VGG16\n",
    "    input_layer = Input(shape=(feature_dim,))\n",
    "    x = Dense(512)(input_layer)  # Reduced from two layers\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    predictions = Dense(1, activation='sigmoid', dtype='float32')(x)\n",
    "    custom_model = Model(inputs=input_layer, outputs=predictions)\n",
    "    \n",
    "    # Compile the custom head model\n",
    "    custom_model.compile(optimizer=Adam(learning_rate=1e-4),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # Early stopping with potentially reduced patience\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    # Train the custom head on extracted features\n",
    "    history = custom_model.fit(train_features, train_labels,batch_size=batch_size,epochs=epochs,validation_data=(val_features, val_labels),callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss, test_accuracy = custom_model.evaluate(test_features, test_labels, verbose=1)\n",
    "    print(f\"\\n{model_name} Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"{model_name} Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = custom_model.predict(test_features, verbose=1)\n",
    "    y_pred = (predictions > 0.5).astype(int).flatten()\n",
    "    y_true = test_labels  # Use extracted labels\n",
    "    \n",
    "    # Compute performance metrics\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    \n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "    precision = precision_score(y_true, y_pred, average='binary')\n",
    "    recall = recall_score(y_true, y_pred, average='binary')\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    labels = list(class_indices.keys())\n",
    "    print(classification_report(y_true, y_pred, target_names=labels))\n",
    "    \n",
    "    # Compute ROC Curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, predictions.flatten())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return {\n",
    "        'model': custom_model,\n",
    "        'history': history.history,\n",
    "        'confusion_matrix': cm,\n",
    "        'roc': (fpr, tpr, roc_auc),\n",
    "        'performance': {'accuracy': test_accuracy, 'f1': f1, 'precision': precision, 'recall': recall},\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def plot_results(results, run_dir):\n",
    "    model_names = list(results.keys())\n",
    "    num_models = len(model_names)\n",
    "    \n",
    "    # 1. Plot Confusion Matrices\n",
    "    fig_cm, axes_cm = plt.subplots(1, num_models, figsize=(5*num_models, 4))\n",
    "    if num_models == 1:\n",
    "        axes_cm = [axes_cm]\n",
    "    for ax, name in zip(axes_cm, model_names):\n",
    "        cm = results[name]['confusion_matrix']\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        ax.set_title(f\"{name} Confusion Matrix\")\n",
    "        tick_marks = np.arange(len(results[name]['labels']))\n",
    "        ax.set_xticks(tick_marks)\n",
    "        ax.set_xticklabels(results[name]['labels'], rotation=45)\n",
    "        ax.set_yticks(tick_marks)\n",
    "        ax.set_yticklabels(results[name]['labels'])\n",
    "        thresh = cm.max() / 2.0\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        fig_cm.colorbar(im, ax=ax)\n",
    "    fig_cm.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig_cm.suptitle(\"Confusion Matrices\", fontsize=16)\n",
    "    plt.savefig(os.path.join(run_dir, \"confusion_matrices.png\"))\n",
    "    plt.close(fig_cm)\n",
    "    \n",
    "    # 2. Plot ROC Curves\n",
    "    fig_roc, axes_roc = plt.subplots(1, num_models, figsize=(5*num_models, 4))\n",
    "    if num_models == 1:\n",
    "        axes_roc = [axes_roc]\n",
    "    for ax, name in zip(axes_roc, model_names):\n",
    "        fpr, tpr, roc_auc = results[name]['roc']\n",
    "        ax.plot(fpr, tpr, lw=2, label=f\"AUC = {roc_auc:.2f}\")\n",
    "        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title(f\"ROC Curve - {name}\")\n",
    "        ax.legend(loc=\"lower right\")\n",
    "    fig_roc.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig_roc.suptitle(\"ROC Curves\", fontsize=16)\n",
    "    plt.savefig(os.path.join(run_dir, \"roc_curves.png\"))\n",
    "    plt.close(fig_roc)\n",
    "    \n",
    "    # 3. Plot Accuracy and Loss Curves for each model\n",
    "    for name in model_names:\n",
    "        history = results[name]['history']\n",
    "        epochs_range = range(1, len(history['accuracy']) + 1)\n",
    "        fig_model, (ax_acc, ax_loss) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        ax_acc.plot(epochs_range, history['accuracy'], marker='o', label='Train Accuracy')\n",
    "        ax_acc.plot(epochs_range, history['val_accuracy'], marker='x', linestyle='--', label='Validation Accuracy')\n",
    "        ax_acc.set_title(f\"{name} Accuracy\")\n",
    "        ax_acc.set_xlabel('Epoch')\n",
    "        ax_acc.set_ylabel('Accuracy')\n",
    "        ax_acc.legend()\n",
    "        \n",
    "        ax_loss.plot(epochs_range, history['loss'], marker='o', label='Train Loss')\n",
    "        ax_loss.plot(epochs_range, history['val_loss'], marker='x', linestyle='--', label='Validation Loss')\n",
    "        ax_loss.set_title(f\"{name} Loss\")\n",
    "        ax_loss.set_xlabel('Epoch')\n",
    "        ax_loss.set_ylabel('Loss')\n",
    "        ax_loss.legend()\n",
    "        \n",
    "        fig_model.suptitle(f\"Accuracy and Loss Curves - {name}\", fontsize=16)\n",
    "        fig_model.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "        plt.savefig(os.path.join(run_dir, f\"{name}_training_curves.png\"))\n",
    "        plt.close(fig_model)\n",
    "    \n",
    "    # 4. Overall Performance Comparison Table\n",
    "    col_labels = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
    "    cell_text = []\n",
    "    for name in model_names:\n",
    "        perf = results[name]['performance']\n",
    "        row = [name,\n",
    "               f\"{perf['accuracy']:.4f}\",\n",
    "               f\"{perf['precision']:.4f}\",\n",
    "               f\"{perf['recall']:.4f}\",\n",
    "               f\"{perf['f1']:.4f}\"]\n",
    "        cell_text.append(row)\n",
    "    \n",
    "    fig_table, ax_table = plt.subplots(figsize=(8, len(model_names)*0.8+1))\n",
    "    ax_table.axis('tight')\n",
    "    ax_table.axis('off')\n",
    "    table = ax_table.table(cellText=cell_text, colLabels=col_labels, loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1, 2)\n",
    "    fig_table.suptitle(\"Overall Performance Comparison\", fontsize=16)\n",
    "    plt.savefig(os.path.join(run_dir, \"performance_table.png\"))\n",
    "    plt.close(fig_table)\n",
    "    \n",
    "    # 5. Save training histories to pickle files\n",
    "    for name in model_names:\n",
    "        history = results[name]['history']\n",
    "        with open(os.path.join(run_dir, f\"{name}_history.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(history, f)\n",
    "    print(\"Training histories saved for each model.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with VGG19...\n",
      "\n",
      "Found 6784 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "class indices: ['Oblique', 'Overriding']\n",
      "Extracting features for training set...\n",
      "Extracting features for validation set...\n",
      "Extracting features for test set...\n",
      "Epoch 1/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7293 - loss: 0.5182 - val_accuracy: 0.9163 - val_loss: 0.2474\n",
      "Epoch 2/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9157 - loss: 0.2536 - val_accuracy: 0.9469 - val_loss: 0.1737\n",
      "Epoch 3/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9465 - loss: 0.1717 - val_accuracy: 0.9564 - val_loss: 0.1396\n",
      "Epoch 4/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9578 - loss: 0.1404 - val_accuracy: 0.9552 - val_loss: 0.1260\n",
      "Epoch 5/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9720 - loss: 0.1072 - val_accuracy: 0.9658 - val_loss: 0.1023\n",
      "Epoch 6/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9755 - loss: 0.0917 - val_accuracy: 0.9693 - val_loss: 0.0921\n",
      "Epoch 7/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9774 - loss: 0.0830 - val_accuracy: 0.9717 - val_loss: 0.0820\n",
      "Epoch 8/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9808 - loss: 0.0697 - val_accuracy: 0.9670 - val_loss: 0.0770\n",
      "Epoch 9/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.0630 - val_accuracy: 0.9729 - val_loss: 0.0712\n",
      "Epoch 10/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0591 - val_accuracy: 0.9776 - val_loss: 0.0644\n",
      "Epoch 11/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0532 - val_accuracy: 0.9741 - val_loss: 0.0665\n",
      "Epoch 12/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0416 - val_accuracy: 0.9811 - val_loss: 0.0557\n",
      "Epoch 13/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9895 - loss: 0.0414 - val_accuracy: 0.9788 - val_loss: 0.0569\n",
      "Epoch 14/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0348 - val_accuracy: 0.9788 - val_loss: 0.0599\n",
      "Epoch 15/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0332 - val_accuracy: 0.9811 - val_loss: 0.0543\n",
      "Epoch 16/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0301 - val_accuracy: 0.9835 - val_loss: 0.0476\n",
      "Epoch 17/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0294 - val_accuracy: 0.9823 - val_loss: 0.0465\n",
      "Epoch 18/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0279 - val_accuracy: 0.9847 - val_loss: 0.0460\n",
      "Epoch 19/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0244 - val_accuracy: 0.9870 - val_loss: 0.0437\n",
      "Epoch 20/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0228 - val_accuracy: 0.9847 - val_loss: 0.0421\n",
      "Epoch 21/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0241 - val_accuracy: 0.9858 - val_loss: 0.0381\n",
      "Epoch 22/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0170 - val_accuracy: 0.9870 - val_loss: 0.0363\n",
      "Epoch 23/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0161 - val_accuracy: 0.9823 - val_loss: 0.0451\n",
      "Epoch 24/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0140 - val_accuracy: 0.9800 - val_loss: 0.0566\n",
      "Epoch 25/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0199 - val_accuracy: 0.9823 - val_loss: 0.0423\n",
      "Epoch 26/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0113 - val_accuracy: 0.9870 - val_loss: 0.0383\n",
      "Epoch 27/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0131 - val_accuracy: 0.9847 - val_loss: 0.0408\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0264 \n",
      "\n",
      "VGG19 Test Loss: 0.0272\n",
      "VGG19 Test Accuracy: 0.9894\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[419   5]\n",
      " [  4 420]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Oblique       0.99      0.99      0.99       424\n",
      "  Overriding       0.99      0.99      0.99       424\n",
      "\n",
      "    accuracy                           0.99       848\n",
      "   macro avg       0.99      0.99      0.99       848\n",
      "weighted avg       0.99      0.99      0.99       848\n",
      "\n",
      "VGG19 custom head model saved.\n",
      "Training histories saved for each model.\n",
      "\n",
      "Training with ResNet50...\n",
      "\n",
      "Found 6784 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "class indices: ['Oblique', 'Overriding']\n",
      "Extracting features for training set...\n",
      "Extracting features for validation set...\n",
      "Extracting features for test set...\n",
      "Epoch 1/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 34ms/step - accuracy: 0.8155 - loss: 0.3934 - val_accuracy: 0.9729 - val_loss: 0.1090\n",
      "Epoch 2/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9722 - loss: 0.1024 - val_accuracy: 0.9906 - val_loss: 0.0575\n",
      "Epoch 3/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9886 - loss: 0.0555 - val_accuracy: 0.9847 - val_loss: 0.0505\n",
      "Epoch 4/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9901 - loss: 0.0431 - val_accuracy: 0.9976 - val_loss: 0.0286\n",
      "Epoch 5/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9962 - loss: 0.0262 - val_accuracy: 0.9953 - val_loss: 0.0231\n",
      "Epoch 6/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9952 - loss: 0.0217 - val_accuracy: 0.9988 - val_loss: 0.0210\n",
      "Epoch 7/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9983 - loss: 0.0143 - val_accuracy: 0.9941 - val_loss: 0.0191\n",
      "Epoch 8/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9972 - loss: 0.0152 - val_accuracy: 0.9965 - val_loss: 0.0164\n",
      "Epoch 9/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9986 - loss: 0.0117 - val_accuracy: 0.9953 - val_loss: 0.0142\n",
      "Epoch 10/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9993 - loss: 0.0099 - val_accuracy: 0.9965 - val_loss: 0.0129\n",
      "Epoch 11/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9989 - loss: 0.0076 - val_accuracy: 0.9976 - val_loss: 0.0114\n",
      "Epoch 12/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9988 - val_loss: 0.0084\n",
      "Epoch 13/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9995 - loss: 0.0066 - val_accuracy: 0.9941 - val_loss: 0.0160\n",
      "Epoch 14/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9999 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 0.0092\n",
      "Epoch 15/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9990 - loss: 0.0060 - val_accuracy: 0.9965 - val_loss: 0.0096\n",
      "Epoch 16/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9994 - loss: 0.0046 - val_accuracy: 0.9976 - val_loss: 0.0079\n",
      "Epoch 17/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9953 - val_loss: 0.0114\n",
      "Epoch 18/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9998 - loss: 0.0029 - val_accuracy: 0.9965 - val_loss: 0.0085\n",
      "Epoch 19/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9996 - loss: 0.0031 - val_accuracy: 0.9988 - val_loss: 0.0064\n",
      "Epoch 20/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0033 - val_accuracy: 0.9965 - val_loss: 0.0102\n",
      "Epoch 21/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 0.9976 - val_loss: 0.0089\n",
      "Epoch 22/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9941 - val_loss: 0.0132\n",
      "Epoch 23/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9965 - val_loss: 0.0087\n",
      "Epoch 24/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9976 - val_loss: 0.0063\n",
      "Epoch 25/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9953 - val_loss: 0.0082\n",
      "Epoch 26/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9999 - loss: 0.0014 - val_accuracy: 0.9929 - val_loss: 0.0130\n",
      "Epoch 27/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.9999 - loss: 0.0021 - val_accuracy: 0.9965 - val_loss: 0.0092\n",
      "Epoch 28/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9988 - val_loss: 0.0049\n",
      "Epoch 29/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 8.2466e-04 - val_accuracy: 0.9988 - val_loss: 0.0033\n",
      "Epoch 30/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9965 - val_loss: 0.0079\n",
      "Epoch 31/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9961 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
      "Epoch 32/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9965 - val_loss: 0.0113\n",
      "Epoch 33/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9953 - val_loss: 0.0111\n",
      "Epoch 34/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9929 - val_loss: 0.0162\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0039   \n",
      "\n",
      "ResNet50 Test Loss: 0.0030\n",
      "ResNet50 Test Accuracy: 1.0000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[424   0]\n",
      " [  0 424]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Oblique       1.00      1.00      1.00       424\n",
      "  Overriding       1.00      1.00      1.00       424\n",
      "\n",
      "    accuracy                           1.00       848\n",
      "   macro avg       1.00      1.00      1.00       848\n",
      "weighted avg       1.00      1.00      1.00       848\n",
      "\n",
      "ResNet50 custom head model saved.\n",
      "Training histories saved for each model.\n",
      "\n",
      "Training with VGG16...\n",
      "\n",
      "Found 6784 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "class indices: ['Oblique', 'Overriding']\n",
      "Extracting features for training set...\n",
      "Extracting features for validation set...\n",
      "Extracting features for test set...\n",
      "Epoch 1/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7552 - loss: 0.4825 - val_accuracy: 0.9009 - val_loss: 0.2630\n",
      "Epoch 2/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9344 - loss: 0.2130 - val_accuracy: 0.9587 - val_loss: 0.1569\n",
      "Epoch 3/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9553 - loss: 0.1519 - val_accuracy: 0.9646 - val_loss: 0.1209\n",
      "Epoch 4/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9691 - loss: 0.1160 - val_accuracy: 0.9764 - val_loss: 0.0965\n",
      "Epoch 5/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.1035 - val_accuracy: 0.9776 - val_loss: 0.0793\n",
      "Epoch 6/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.0829 - val_accuracy: 0.9800 - val_loss: 0.0722\n",
      "Epoch 7/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0650 - val_accuracy: 0.9811 - val_loss: 0.0628\n",
      "Epoch 8/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9877 - loss: 0.0549 - val_accuracy: 0.9835 - val_loss: 0.0590\n",
      "Epoch 9/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0481 - val_accuracy: 0.9847 - val_loss: 0.0534\n",
      "Epoch 10/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0412 - val_accuracy: 0.9847 - val_loss: 0.0528\n",
      "Epoch 11/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0414 - val_accuracy: 0.9847 - val_loss: 0.0505\n",
      "Epoch 12/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0311 - val_accuracy: 0.9870 - val_loss: 0.0429\n",
      "Epoch 13/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0274 - val_accuracy: 0.9882 - val_loss: 0.0371\n",
      "Epoch 14/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0293 - val_accuracy: 0.9906 - val_loss: 0.0343\n",
      "Epoch 15/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0265 - val_accuracy: 0.9882 - val_loss: 0.0362\n",
      "Epoch 16/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0221 - val_accuracy: 0.9870 - val_loss: 0.0379\n",
      "Epoch 17/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0221 - val_accuracy: 0.9917 - val_loss: 0.0275\n",
      "Epoch 18/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0163 - val_accuracy: 0.9894 - val_loss: 0.0267\n",
      "Epoch 19/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0183 - val_accuracy: 0.9906 - val_loss: 0.0269\n",
      "Epoch 20/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0169 - val_accuracy: 0.9882 - val_loss: 0.0298\n",
      "Epoch 21/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0157 - val_accuracy: 0.9870 - val_loss: 0.0377\n",
      "Epoch 22/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0167 - val_accuracy: 0.9917 - val_loss: 0.0200\n",
      "Epoch 23/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0118 - val_accuracy: 0.9929 - val_loss: 0.0197\n",
      "Epoch 24/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0105 - val_accuracy: 0.9906 - val_loss: 0.0254\n",
      "Epoch 25/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0116 - val_accuracy: 0.9917 - val_loss: 0.0218\n",
      "Epoch 26/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0123 - val_accuracy: 0.9894 - val_loss: 0.0226\n",
      "Epoch 27/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0087 - val_accuracy: 0.9906 - val_loss: 0.0233\n",
      "Epoch 28/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0117 - val_accuracy: 0.9917 - val_loss: 0.0189\n",
      "Epoch 29/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0080 - val_accuracy: 0.9941 - val_loss: 0.0154\n",
      "Epoch 30/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0063 - val_accuracy: 0.9929 - val_loss: 0.0173\n",
      "Epoch 31/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0054 - val_accuracy: 0.9906 - val_loss: 0.0175\n",
      "Epoch 32/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0087 - val_accuracy: 0.9929 - val_loss: 0.0180\n",
      "Epoch 33/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0069 - val_accuracy: 0.9929 - val_loss: 0.0170\n",
      "Epoch 34/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0048 - val_accuracy: 0.9894 - val_loss: 0.0276\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0082 \n",
      "\n",
      "VGG16 Test Loss: 0.0139\n",
      "VGG16 Test Accuracy: 0.9953\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[424   0]\n",
      " [  4 420]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Oblique       0.99      1.00      1.00       424\n",
      "  Overriding       1.00      0.99      1.00       424\n",
      "\n",
      "    accuracy                           1.00       848\n",
      "   macro avg       1.00      1.00      1.00       848\n",
      "weighted avg       1.00      1.00      1.00       848\n",
      "\n",
      "VGG16 custom head model saved.\n",
      "Training histories saved for each model.\n",
      "\n",
      "Training with MobileNetV2...\n",
      "\n",
      "Found 6784 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "class indices: ['Oblique', 'Overriding']\n",
      "Extracting features for training set...\n",
      "Extracting features for validation set...\n",
      "Extracting features for test set...\n",
      "Epoch 1/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7916 - loss: 0.4412 - val_accuracy: 0.9623 - val_loss: 0.1643\n",
      "Epoch 2/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9574 - loss: 0.1513 - val_accuracy: 0.9741 - val_loss: 0.0990\n",
      "Epoch 3/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9724 - loss: 0.1047 - val_accuracy: 0.9835 - val_loss: 0.0701\n",
      "Epoch 4/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9813 - loss: 0.0734 - val_accuracy: 0.9858 - val_loss: 0.0585\n",
      "Epoch 5/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9900 - loss: 0.0507 - val_accuracy: 0.9870 - val_loss: 0.0507\n",
      "Epoch 6/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9917 - loss: 0.0427 - val_accuracy: 0.9882 - val_loss: 0.0429\n",
      "Epoch 7/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9930 - loss: 0.0359 - val_accuracy: 0.9906 - val_loss: 0.0370\n",
      "Epoch 8/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.0309 - val_accuracy: 0.9906 - val_loss: 0.0328\n",
      "Epoch 9/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9970 - loss: 0.0245 - val_accuracy: 0.9894 - val_loss: 0.0319\n",
      "Epoch 10/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0193 - val_accuracy: 0.9906 - val_loss: 0.0287\n",
      "Epoch 11/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0162 - val_accuracy: 0.9929 - val_loss: 0.0270\n",
      "Epoch 12/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9978 - loss: 0.0168 - val_accuracy: 0.9917 - val_loss: 0.0260\n",
      "Epoch 13/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9987 - loss: 0.0117 - val_accuracy: 0.9882 - val_loss: 0.0312\n",
      "Epoch 14/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0114 - val_accuracy: 0.9894 - val_loss: 0.0240\n",
      "Epoch 15/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0141 - val_accuracy: 0.9906 - val_loss: 0.0205\n",
      "Epoch 16/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0113 - val_accuracy: 0.9894 - val_loss: 0.0238\n",
      "Epoch 17/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0076 - val_accuracy: 0.9929 - val_loss: 0.0196\n",
      "Epoch 18/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0060 - val_accuracy: 0.9941 - val_loss: 0.0171\n",
      "Epoch 19/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0065 - val_accuracy: 0.9917 - val_loss: 0.0215\n",
      "Epoch 20/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0086 - val_accuracy: 0.9917 - val_loss: 0.0173\n",
      "Epoch 21/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0041 - val_accuracy: 0.9929 - val_loss: 0.0167\n",
      "Epoch 22/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0043 - val_accuracy: 0.9906 - val_loss: 0.0201\n",
      "Epoch 23/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 0.0048 - val_accuracy: 0.9929 - val_loss: 0.0175\n",
      "Epoch 24/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0047 - val_accuracy: 0.9941 - val_loss: 0.0173\n",
      "Epoch 25/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 0.0039 - val_accuracy: 0.9823 - val_loss: 0.0387\n",
      "Epoch 26/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0058 - val_accuracy: 0.9917 - val_loss: 0.0177\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0115 \n",
      "\n",
      "MobileNetV2 Test Loss: 0.0203\n",
      "MobileNetV2 Test Accuracy: 0.9965\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[424   0]\n",
      " [  3 421]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Oblique       0.99      1.00      1.00       424\n",
      "  Overriding       1.00      0.99      1.00       424\n",
      "\n",
      "    accuracy                           1.00       848\n",
      "   macro avg       1.00      1.00      1.00       848\n",
      "weighted avg       1.00      1.00      1.00       848\n",
      "\n",
      "MobileNetV2 custom head model saved.\n",
      "Training histories saved for each model.\n",
      "\n",
      "Training with Xception...\n",
      "\n",
      "Found 6784 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "class indices: ['Oblique', 'Overriding']\n",
      "Extracting features for training set...\n",
      "Extracting features for validation set...\n",
      "Extracting features for test set...\n",
      "Epoch 1/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.8190 - loss: 0.3912 - val_accuracy: 0.9634 - val_loss: 0.2258\n",
      "Epoch 2/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9648 - loss: 0.1218 - val_accuracy: 0.9682 - val_loss: 0.1052\n",
      "Epoch 3/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9799 - loss: 0.0763 - val_accuracy: 0.9800 - val_loss: 0.0684\n",
      "Epoch 4/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0484 - val_accuracy: 0.9835 - val_loss: 0.0517\n",
      "Epoch 5/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9919 - loss: 0.0383 - val_accuracy: 0.9882 - val_loss: 0.0418\n",
      "Epoch 6/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9951 - loss: 0.0303 - val_accuracy: 0.9882 - val_loss: 0.0415\n",
      "Epoch 7/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9985 - loss: 0.0219 - val_accuracy: 0.9870 - val_loss: 0.0364\n",
      "Epoch 8/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9947 - loss: 0.0204 - val_accuracy: 0.9894 - val_loss: 0.0385\n",
      "Epoch 9/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9965 - loss: 0.0186 - val_accuracy: 0.9847 - val_loss: 0.0347\n",
      "Epoch 10/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9999 - loss: 0.0118 - val_accuracy: 0.9906 - val_loss: 0.0315\n",
      "Epoch 11/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0098 - val_accuracy: 0.9906 - val_loss: 0.0260\n",
      "Epoch 12/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9990 - loss: 0.0101 - val_accuracy: 0.9917 - val_loss: 0.0295\n",
      "Epoch 13/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0078 - val_accuracy: 0.9906 - val_loss: 0.0264\n",
      "Epoch 14/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9979 - loss: 0.0085 - val_accuracy: 0.9941 - val_loss: 0.0240\n",
      "Epoch 15/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0055 - val_accuracy: 0.9906 - val_loss: 0.0248\n",
      "Epoch 16/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0061 - val_accuracy: 0.9929 - val_loss: 0.0237\n",
      "Epoch 17/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9999 - loss: 0.0051 - val_accuracy: 0.9941 - val_loss: 0.0248\n",
      "Epoch 18/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0072 - val_accuracy: 0.9906 - val_loss: 0.0259\n",
      "Epoch 19/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9998 - loss: 0.0044 - val_accuracy: 0.9941 - val_loss: 0.0243\n",
      "Epoch 20/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9870 - val_loss: 0.0348\n",
      "Epoch 21/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9995 - loss: 0.0044 - val_accuracy: 0.9941 - val_loss: 0.0228\n",
      "Epoch 22/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9917 - val_loss: 0.0233\n",
      "Epoch 23/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9998 - loss: 0.0024 - val_accuracy: 0.9906 - val_loss: 0.0223\n",
      "Epoch 24/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9906 - val_loss: 0.0308\n",
      "Epoch 25/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0068 - val_accuracy: 0.9906 - val_loss: 0.0225\n",
      "Epoch 26/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9999 - loss: 0.0019 - val_accuracy: 0.9929 - val_loss: 0.0240\n",
      "Epoch 27/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9906 - val_loss: 0.0179\n",
      "Epoch 28/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9917 - val_loss: 0.0223\n",
      "Epoch 29/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9941 - val_loss: 0.0178\n",
      "Epoch 30/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9990 - loss: 0.0042 - val_accuracy: 0.9847 - val_loss: 0.0568\n",
      "Epoch 31/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9995 - loss: 0.0034 - val_accuracy: 0.9941 - val_loss: 0.0139\n",
      "Epoch 32/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.9941 - val_loss: 0.0183\n",
      "Epoch 33/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0024 - val_accuracy: 0.9917 - val_loss: 0.0278\n",
      "Epoch 34/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9917 - val_loss: 0.0195\n",
      "Epoch 35/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9929 - val_loss: 0.0185\n",
      "Epoch 36/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9998 - loss: 0.0020 - val_accuracy: 0.9929 - val_loss: 0.0247\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0135     \n",
      "\n",
      "Xception Test Loss: 0.0137\n",
      "Xception Test Accuracy: 0.9953\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[421   3]\n",
      " [  1 423]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Oblique       1.00      0.99      1.00       424\n",
      "  Overriding       0.99      1.00      1.00       424\n",
      "\n",
      "    accuracy                           1.00       848\n",
      "   macro avg       1.00      1.00      1.00       848\n",
      "weighted avg       1.00      1.00      1.00       848\n",
      "\n",
      "Xception custom head model saved.\n",
      "Training histories saved for each model.\n",
      "\n",
      "Training with EfficientNetB0...\n",
      "\n",
      "Found 6784 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "class indices: ['Oblique', 'Overriding']\n",
      "Extracting features for training set...\n",
      "Extracting features for validation set...\n",
      "Extracting features for test set...\n",
      "Epoch 1/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8371 - loss: 0.3531 - val_accuracy: 0.9800 - val_loss: 0.1270\n",
      "Epoch 2/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9763 - loss: 0.0839 - val_accuracy: 0.9906 - val_loss: 0.0493\n",
      "Epoch 3/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9905 - loss: 0.0457 - val_accuracy: 0.9906 - val_loss: 0.0369\n",
      "Epoch 4/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9950 - loss: 0.0304 - val_accuracy: 0.9917 - val_loss: 0.0266\n",
      "Epoch 5/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9961 - loss: 0.0236 - val_accuracy: 0.9917 - val_loss: 0.0223\n",
      "Epoch 6/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0167 - val_accuracy: 0.9929 - val_loss: 0.0219\n",
      "Epoch 7/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0135 - val_accuracy: 0.9965 - val_loss: 0.0173\n",
      "Epoch 8/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0129 - val_accuracy: 0.9941 - val_loss: 0.0162\n",
      "Epoch 9/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0088 - val_accuracy: 0.9965 - val_loss: 0.0136\n",
      "Epoch 10/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0100 - val_accuracy: 0.9965 - val_loss: 0.0143\n",
      "Epoch 11/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0066 - val_accuracy: 0.9965 - val_loss: 0.0145\n",
      "Epoch 12/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0058 - val_accuracy: 0.9953 - val_loss: 0.0146\n",
      "Epoch 13/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0059 - val_accuracy: 0.9953 - val_loss: 0.0160\n",
      "Epoch 14/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 0.0039 - val_accuracy: 0.9953 - val_loss: 0.0145\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0087 \n",
      "\n",
      "EfficientNetB0 Test Loss: 0.0083\n",
      "EfficientNetB0 Test Accuracy: 0.9988\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[423   1]\n",
      " [  0 424]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Oblique       1.00      1.00      1.00       424\n",
      "  Overriding       1.00      1.00      1.00       424\n",
      "\n",
      "    accuracy                           1.00       848\n",
      "   macro avg       1.00      1.00      1.00       848\n",
      "weighted avg       1.00      1.00      1.00       848\n",
      "\n",
      "EfficientNetB0 custom head model saved.\n",
      "Training histories saved for each model.\n",
      "\n",
      "Training with DenseNet121...\n",
      "\n",
      "Found 6784 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "Found 848 images belonging to 2 classes.\n",
      "class indices: ['Oblique', 'Overriding']\n",
      "Extracting features for training set...\n",
      "Extracting features for validation set...\n",
      "Extracting features for test set...\n",
      "Epoch 1/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7873 - loss: 0.4335 - val_accuracy: 0.9599 - val_loss: 0.1606\n",
      "Epoch 2/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9596 - loss: 0.1485 - val_accuracy: 0.9705 - val_loss: 0.0956\n",
      "Epoch 3/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9804 - loss: 0.0882 - val_accuracy: 0.9800 - val_loss: 0.0671\n",
      "Epoch 4/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9832 - loss: 0.0675 - val_accuracy: 0.9835 - val_loss: 0.0551\n",
      "Epoch 5/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9888 - loss: 0.0545 - val_accuracy: 0.9847 - val_loss: 0.0445\n",
      "Epoch 6/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9895 - loss: 0.0411 - val_accuracy: 0.9882 - val_loss: 0.0389\n",
      "Epoch 7/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0351 - val_accuracy: 0.9894 - val_loss: 0.0334\n",
      "Epoch 8/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0271 - val_accuracy: 0.9847 - val_loss: 0.0362\n",
      "Epoch 9/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0247 - val_accuracy: 0.9882 - val_loss: 0.0287\n",
      "Epoch 10/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0172 - val_accuracy: 0.9906 - val_loss: 0.0269\n",
      "Epoch 11/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9979 - loss: 0.0178 - val_accuracy: 0.9929 - val_loss: 0.0246\n",
      "Epoch 12/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9962 - loss: 0.0191 - val_accuracy: 0.9906 - val_loss: 0.0238\n",
      "Epoch 13/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0151 - val_accuracy: 0.9929 - val_loss: 0.0207\n",
      "Epoch 14/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0109 - val_accuracy: 0.9917 - val_loss: 0.0209\n",
      "Epoch 15/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0119 - val_accuracy: 0.9906 - val_loss: 0.0206\n",
      "Epoch 16/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0092 - val_accuracy: 0.9929 - val_loss: 0.0180\n",
      "Epoch 17/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0079 - val_accuracy: 0.9906 - val_loss: 0.0198\n",
      "Epoch 18/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 0.0068 - val_accuracy: 0.9929 - val_loss: 0.0201\n",
      "Epoch 19/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0081 - val_accuracy: 0.9953 - val_loss: 0.0150\n",
      "Epoch 20/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0067 - val_accuracy: 0.9929 - val_loss: 0.0165\n",
      "Epoch 21/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0062 - val_accuracy: 0.9965 - val_loss: 0.0142\n",
      "Epoch 22/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0043 - val_accuracy: 0.9929 - val_loss: 0.0171\n",
      "Epoch 23/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0047 - val_accuracy: 0.9941 - val_loss: 0.0160\n",
      "Epoch 24/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0039 - val_accuracy: 0.9941 - val_loss: 0.0146\n",
      "Epoch 25/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0035 - val_accuracy: 0.9941 - val_loss: 0.0150\n",
      "Epoch 26/50\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0055 - val_accuracy: 0.9906 - val_loss: 0.0186\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0196 \n",
      "\n",
      "DenseNet121 Test Loss: 0.0161\n",
      "DenseNet121 Test Accuracy: 0.9953\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[422   2]\n",
      " [  2 422]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Oblique       1.00      1.00      1.00       424\n",
      "  Overriding       1.00      1.00      1.00       424\n",
      "\n",
      "    accuracy                           1.00       848\n",
      "   macro avg       1.00      1.00      1.00       848\n",
      "weighted avg       1.00      1.00      1.00       848\n",
      "\n",
      "DenseNet121 custom head model saved.\n",
      "Training histories saved for each model.\n",
      "All outputs saved to directory: D:/Learning/University of sadat/Grade 4/Semester 2/06- Graduation Project/Coding/runs_codes\\2025-03-20_17-17-27\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Update the main execution block to use the new function as is\n",
    "if __name__ == \"__main__\":\n",
    "    Base_Folder = 'D:/Learning/University of sadat/Grade 4/Semester 2/06- Graduation Project/Coding/' \n",
    "    split_dataset_dir = f'{Base_Folder}00- The DataSet/Dataset_split'\n",
    "    \n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    run_dir = os.path.join(f'{Base_Folder}runs_codes', current_time)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    # # Copy current script to run directory\n",
    "    # script_path = os.path.abspath(__file__)\n",
    "    # script_name = os.path.basename(script_path)\n",
    "    # shutil.copy(script_path, os.path.join(run_dir, script_name))\n",
    "    def get_notebook_path():\n",
    "        ipython = get_ipython()\n",
    "        if ipython is None:\n",
    "            raise RuntimeError(\"Not running in Jupyter.\")\n",
    "        # VS Code specific (may not work in all environments)\n",
    "        if '__vsc_ipynb_file__' in ipython.user_ns:\n",
    "            return Path(ipython.user_ns['__vsc_ipynb_file__'])\n",
    "        # Fallback or other environments\n",
    "        try:\n",
    "            return Path(ipython.startup_scripts[0])\n",
    "        except:\n",
    "            raise RuntimeError(\"Could not determine notebook path.\")\n",
    "\n",
    "    notebook_path = get_notebook_path()\n",
    "    notebook_name = notebook_path.name\n",
    "    # Create the destination path\n",
    "    destination_path = os.path.join(run_dir, notebook_name)\n",
    "\n",
    "    # Copy the notebook to the specified directory\n",
    "    shutil.copy(notebook_path, destination_path)\n",
    "    \n",
    "    batch_size = 32  \n",
    "    epochs = 20\n",
    "    \n",
    "    results = {}\n",
    "    models = {\n",
    "        'VGG19': vgg19_preprocess,\n",
    "        'ResNet50': resnet50_preprocess,\n",
    "        'VGG16': vgg16_preprocess,\n",
    "        'MobileNetV2': mobilenetv2_preprocess,\n",
    "        'Xception': xception_preprocess,\n",
    "        'EfficientNetB0': efficientnetb0_preprocess,\n",
    "        'DenseNet121': densenet121_preprocess\n",
    "    }\n",
    "    \n",
    "    for model_name, preprocess in models.items():\n",
    "        results[model_name] = train_and_evaluate_model(model_name, preprocess)\n",
    "        \n",
    "        # Save the custom head model instead\n",
    "        results[model_name]['model'].save(os.path.join(run_dir, f\"{model_name}_custom_model.h5\"))\n",
    "        print(f\"{model_name} custom head model saved.\")\n",
    "    \n",
    "    plot_results(results, run_dir)\n",
    "    print(f\"All outputs saved to directory: {run_dir}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ai_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
